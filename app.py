import streamlit as st
import graphviz
import json
from streamlit_mic_recorder import mic_recorder
from core.schema import OntologyModel, LayerConfig, AccessLevel
from core.engine import HozoEngine
from core.storage import OntologyStorage

# 1. åˆæœŸè¨­å®šã¨æ°¸ç¶šåŒ–ã®æº–å‚™
storage = OntologyStorage()
st.set_page_config(
    page_title="1216 Hozo AI Architect",
    page_icon="ğŸ™ï¸",
    layout="wide"
)

# 2. ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã®åˆæœŸåŒ–
if "model" not in st.session_state:
    loaded_data = storage.load()
    # ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã™ã‚‹å ´åˆã®ã¿ãƒ­ãƒ¼ãƒ‰ã€ç©ºã®å ´åˆã¯æ–°è¦ä½œæˆ
    if loaded_data.get("nodes"):
        model = OntologyModel(**loaded_data)
    else:
        # åˆæœŸçŠ¶æ…‹ã®ãƒ¬ã‚¤ãƒ¤ãƒ¼å®šç¾©
        model = OntologyModel()
        model.layers = {
            "Core": LayerConfig(name="Core", access=AccessLevel.LOCKED, description="åŸºæœ¬æ¦‚å¿µå±¤"),
            "Medical": LayerConfig(name="Medical", access=AccessLevel.OPEN, description="åŒ»ç™‚ãƒ‰ãƒ¡ã‚¤ãƒ³å±¤"),
            "User": LayerConfig(name="User", access=AccessLevel.OPEN, description="è‡ªç”±è¨˜è¿°å±¤")
        }
    st.session_state.model = model
    st.session_state.engine = HozoEngine(st.session_state.model)

# --- UI ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ ---

st.title("ğŸ™ï¸ Hozo Voice-Driven Ontology Architect")
# æ¥ç¶šä¸­ã®AIãƒ¢ãƒ‡ãƒ«åã‚’è¡¨ç¤ºï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
if hasattr(st.session_state.engine, 'model_id'):
    st.caption(f"ğŸš€ AI Engine: `{st.session_state.engine.model_id}` connected.")
st.markdown("---")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼: ãƒ¬ã‚¤ãƒ¤ãƒ¼ç®¡ç†ã¨ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
with st.sidebar:
    st.header("âš™ï¸ System Control")
    
    st.subheader("Layer Status")
    for l_name, l_cfg in st.session_state.model.layers.items():
        icon = "ğŸ”’" if l_cfg.access == AccessLevel.LOCKED else "ğŸ”“"
        st.write(f"{icon} **{l_name}**: `{l_cfg.access.value}`")
    
    st.divider()
    
    st.subheader("ğŸ’¾ Data Management")
    if st.button("Save Current Model"):
        # Pydantic V2: dict() ã‚’ model_dump() ã«ä¿®æ­£
        storage.save(st.session_state.model.model_dump())
        st.success("Saved to data/ontology_model.json")
    
    # JSONãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã¨ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    # Pydantic V2: dict() ã‚’ model_dump() ã«ä¿®æ­£
    json_output = json.dumps(st.session_state.model.model_dump(), indent=2, ensure_ascii=False)
    st.download_button(
        label="Download JSON",
        data=json_output,
        file_name="hozo_model.json",
        mime="application/json"
    )

# ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢: å…¥åŠ›ã¨å¯è¦–åŒ–
col_input, col_viz = st.columns([1, 2])

with col_input:
    st.subheader("ğŸ¤ Command Input")
    
    # éŸ³å£°å…¥åŠ›
    audio = mic_recorder(
        start_prompt="Click to Start Recording",
        stop_prompt="Stop Recording",
        key='recorder'
    )
    
    if audio:
        st.audio(audio['bytes'])
        st.info("Audio captured. Analyzing intent...")
    
    user_input = st.text_area(
        "Voice to Text / Manual Command:",
        placeholder="ä¾‹ï¼šåŒ»ç™‚ãƒ¬ã‚¤ãƒ¤ãƒ¼ã«ã€äººé–“ã‹ã‚‰æ´¾ç”Ÿã™ã‚‹æ‚£è€…ã¨ã„ã†ãƒ­ãƒ¼ãƒ«æ¦‚å¿µã‚’è¿½åŠ ã—ã¦",
        height=100
    )
    
    if st.button("Execute Logic", type="primary"):
        if user_input:
            with st.spinner("Gemini is reasoning..."):
                result = st.session_state.engine.execute(user_input)
                
                if result["status"] == "success":
                    st.success(f"Action: {result.get('action', 'ADD')} Success!")
                    st.balloons()
                    
                    # AIã‹ã‚‰ã®è¿½åŠ ææ¡ˆã‚’è¡¨ç¤º
                    if result.get("suggestions"):
                        st.write("ğŸ’¡ **AI Suggestions for expansion:**")
                        for suggestion in result["suggestions"]:
                            st.info(f"â€¢ {suggestion}")
                    
                    # æ“ä½œã®ãŸã³ã«è‡ªå‹•ä¿å­˜ (dict -> model_dump)
                    storage.save(st.session_state.model.model_dump())
                else:
                    st.error(f"Error: {result['message']}")
        else:
            st.warning("Please enter a command.")

with col_viz:
    st.subheader("ğŸ“Š Knowledge Structure Visualization")
    
    # Graphvizã«ã‚ˆã‚‹æç”»
    dot = graphviz.Digraph()
    dot.attr(rankdir='BT', size='8,8') # Bottom-to-Top (æ³•é€ ã®éšå±¤é †)
    
    if not st.session_state.model.nodes:
        st.info("No nodes yet. Add a concept to start visualizing.")
    else:
        for node_id, node in st.session_state.model.nodes.items():
            # æ³•é€ ã®ãƒ«ãƒ¼ãƒ«ï¼šBasicã¯é’ã€Roleã¯ã‚ªãƒ¬ãƒ³ã‚¸
            color = "#E1F5FE" if node.type == "basic" else "#FFF3E0"
            edge_color = "#01579B" if node.type == "basic" else "#E65100"
            shape = "ellipse" if node.type == "basic" else "box"
            
            label = f"<<B>{node.label}</B><BR/><FONT POINT-SIZE='10'>({node.type})</FONT>>"
            dot.node(node_id, label, style="filled", fillcolor=color, color=edge_color, shape=shape)
            
            # è¦ªæ¦‚å¿µã¸ã®ãƒªãƒ³ã‚¯ï¼ˆisaé–¢ä¿‚ï¼‰
            if node.parent_id and node.parent_id in st.session_state.model.nodes:
                dot.edge(node_id, node.parent_id, label="isa", color="#9E9E9E")

        st.graphviz_chart(dot, use_container_width=True)

# 3. ãƒ‡ãƒãƒƒã‚°ç”¨ã‚¨ãƒ‡ã‚£ã‚¿ï¼ˆæœ€ä¸‹éƒ¨ï¼‰
with st.expander("ğŸ” View Raw Model Schema"):
    # Pydantic V2: dict() ã‚’ model_dump() ã«ä¿®æ­£
    st.json(st.session_state.model.model_dump())